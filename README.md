# ðŸ“Š Customer Churn Prediction Dashboard

An end-to-end **Machine Learning project** for predicting customer churn using **Flask (backend)**, **React + Vite (frontend)**, and **XGBoost/Logistic Regression**.  
The project also includes **EDA + Feature Selection** in Jupyter Notebook for full reproducibility.

---

## ðŸš€ Features
- Interactive **dashboard** to explore churn behavior:
  - Churn by **Contract type**, **Tenure buckets**, **Monthly charges**
  - Feature importance (from SHAP + model feature importances)
- **Single prediction** â†’ Enter customer details and get churn probability
- **Batch prediction** â†’ Upload CSV and view predictions for multiple customers
- **Model performance comparison** (Accuracy + AUC)
- **Explainability** â†’ SHAP-based model interpretation

---

## ðŸ“‚ Project Structure

churn-predictor/
â”œâ”€â”€ backend/ 
â”‚ â”œâ”€â”€ app.py
â”‚ â”œâ”€â”€ train_model.py
â”‚ â”œâ”€â”€ model.pkl
â”‚ â”œâ”€â”€ Telco_Cust_Churn.csv
â”‚ â”œâ”€â”€ metrics.json
â”‚ â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/ 
â”‚ â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ package.json
â”‚ â””â”€â”€ vite.config.js
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ churn_analysis.ipynb
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore


---

## âš™ï¸ Setup Instructions

### ðŸ”¹ Backend (Flask)
1. Navigate to backend folder:
   ```bash
   cd backend
2. Create virtual environment & install dependencies:

     python -m venv .venv
     source .venv/bin/activate   
     pip install -r requirements.txt

3.Run the Flask server:

     python app.py

###ðŸ”¹ Frontend (React + Vite)

1.Navigate to frontend folder:
  cd frontend

2.Install dependencies:
  npm install

3.Start development server:
  npm run dev

### ðŸ“’ Notebook

The notebooks/ folder contains:
churn_analysis.ipynb â†’ Includes EDA, feature engineering, model experimentation, and feature selection.
This ensures the full workflow is transparent â€” from data understanding to deployment.

### ðŸ“Š Model Training

To retrain the model:
cd backend
python train_model.py


This generates:
model.pkl â†’ Trained pipeline (preprocessing + model)
metrics.json â†’ Performance metrics + feature importances

## ðŸ› ï¸ Tech Stack

-> Backend â†’ Python, Flask, Scikit-learn, XGBoost, Pandas, SHAP

-> Frontend â†’ React, Vite, Chart.js, Axios, TailwindCSS

-> Notebook â†’ Jupyter (EDA + Feature Engineering)

